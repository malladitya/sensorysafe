AZURE AI INTEGRATION GUIDE FOR IMAGINE CUP
Rivo Navigation - Sensory-Friendly Navigation App

===========================================

TABLE OF CONTENTS
1. Overview
2. Option 1: Azure AI Language (Sentiment Analysis) - EASIEST
3. Option 2: Azure OpenAI Service - MOST IMPRESSIVE
4. Option 3: Azure Anomaly Detector - UNIQUE
5. Quick Setup Instructions
6. Code Implementation
7. Demo Talking Points

===========================================

1. OVERVIEW

This guide shows you 3 easy ways to integrate Azure AI into your Rivo Navigation app for Imagine Cup. Each option takes 5-10 minutes to set up and will impress judges.

Why Azure AI for Imagine Cup?
‚úì Bonus points from judges
‚úì Shows technical depth
‚úì Free student credits available
‚úì Easy to implement
‚úì Makes your demo stand out

===========================================

2. OPTION 1: AZURE AI LANGUAGE (SENTIMENT ANALYSIS) ‚≠ê RECOMMENDED

DIFFICULTY: Easy (5 minutes)
COST: Free tier available
IMPACT: High

WHAT IT DOES:
Analyzes user report descriptions to detect stress levels and prioritize high-stress areas automatically.

USE CASE IN YOUR APP:
When users report "Heavy traffic, very loud, stressful" ‚Üí AI detects negative sentiment ‚Üí Increases danger level of that zone

SETUP STEPS:
1. Go to portal.azure.com
2. Click "Create a resource"
3. Search "Language Service"
4. Click Create
5. Fill in:
   - Resource name: Rivo-language
   - Region: East US
   - Pricing tier: Free F0
6. Click "Review + Create"
7. Copy your KEY and ENDPOINT from the resource

CODE TO ADD:

async function analyzeSentiment(description) {
  const endpoint = 'YOUR_ENDPOINT_HERE';
  const key = 'YOUR_KEY_HERE';
  
  const response = await fetch(`${endpoint}/text/analytics/v3.1/sentiment`, {
    method: 'POST',
    headers: {
      'Ocp-Apim-Subscription-Key': key,
      'Content-Type': 'application/json'
    },
    body: JSON.stringify({
      documents: [{ 
        id: '1', 
        language: 'en',
        text: description 
      }]
    })
  });
  
  const data = await response.json();
  return data.documents[0].sentiment; // Returns: positive, negative, or neutral
}

// Integrate with your existing report function
function reportNoiseZone(coords, level, description) {
  const sentiment = await analyzeSentiment(description);
  
  // Adjust level based on sentiment
  if (sentiment === 'negative') level = Math.min(1.0, level + 0.2);
  if (sentiment === 'positive') level = Math.max(0.0, level - 0.1);
  
  // Continue with existing code...
  const report = { coords, level, description, sentiment, timestamp: Date.now() };
  communityReports.noise.push(report);
}

DEMO TALKING POINT:
"We use Azure AI Language to analyze community reports in real-time. When users describe areas as 'stressful' or 'overwhelming,' our AI automatically increases the danger level of those zones, making predictions more accurate."

===========================================

3. OPTION 2: AZURE OPENAI SERVICE ‚≠ê MOST IMPRESSIVE

DIFFICULTY: Medium (10 minutes)
COST: Pay-as-you-go (students get $100 credit)
IMPACT: Very High

WHAT IT DOES:
Generates personalized route recommendations using GPT-3.5

USE CASE IN YOUR APP:
Provides natural language explanations for why a route is comfortable or suggests alternative times to travel

SETUP STEPS:
1. Go to portal.azure.com
2. Search "Azure OpenAI"
3. Click "Create" (may need to apply for access - students get priority)
4. Once approved, deploy GPT-3.5-turbo model
5. Copy your KEY and ENDPOINT

CODE TO ADD:

async function getAIRecommendation(userPreferences, location, time) {
  const endpoint = 'YOUR_ENDPOINT_HERE';
  const key = 'YOUR_KEY_HERE';
  
  const prompt = `You are a sensory-friendly navigation assistant. 
  User wants to avoid: ${userPreferences}
  Current location: ${location}
  Time: ${time}
  
  Provide a brief, helpful recommendation (2-3 sentences) about the best route or time to travel.`;
  
  const response = await fetch(`${endpoint}/openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-05-15`, {
    method: 'POST',
    headers: {
      'api-key': key,
      'Content-Type': 'application/json'
    },
    body: JSON.stringify({
      messages: [
        { role: 'system', content: 'You are a helpful navigation assistant for people with sensory sensitivities.' },
        { role: 'user', content: prompt }
      ],
      max_tokens: 150,
      temperature: 0.7
    })
  });
  
  const data = await response.json();
  return data.choices[0].message.content;
}

// Add to your UI
async function showAIRecommendation() {
  const prefs = getSelectedPreferences(); // Your existing function
  const location = getCurrentLocation(); // Your existing function
  const time = new Date().toLocaleTimeString();
  
  const recommendation = await getAIRecommendation(prefs, location, time);
  
  // Display in a popup or alert
  alert(`AI Recommendation:\n\n${recommendation}`);
}

DEMO TALKING POINT:
"We've integrated Azure OpenAI to provide personalized, natural language recommendations. The AI understands user preferences and suggests the best routes and times based on real-time conditions."

===========================================

4. OPTION 3: AZURE ANOMALY DETECTOR ‚≠ê UNIQUE

DIFFICULTY: Easy (5 minutes)
COST: Free tier available
IMPACT: High (unique feature)

WHAT IT DOES:
Detects unusual spikes in noise or crowd levels and alerts users

USE CASE IN YOUR APP:
Identifies when an area suddenly becomes much noisier than usual (e.g., unexpected event, accident)

SETUP STEPS:
1. Go to portal.azure.com
2. Search "Anomaly Detector"
3. Click Create
4. Fill in details (use Free F0 tier)
5. Copy KEY and ENDPOINT

CODE TO ADD:

async function detectAnomalies(locationReports) {
  const endpoint = 'YOUR_ENDPOINT_HERE';
  const key = 'YOUR_KEY_HERE';
  
  // Format your reports as time series data
  const series = locationReports.map(r => ({
    timestamp: new Date(r.timestamp).toISOString(),
    value: r.level
  }));
  
  const response = await fetch(`${endpoint}/anomalydetector/v1.0/timeseries/entire/detect`, {
    method: 'POST',
    headers: {
      'Ocp-Apim-Subscription-Key': key,
      'Content-Type': 'application/json'
    },
    body: JSON.stringify({
      series: series,
      granularity: 'hourly',
      sensitivity: 95
    })
  });
  
  const data = await response.json();
  return data.isAnomaly; // Array of true/false for each point
}

// Check for anomalies periodically
setInterval(async () => {
  const recentReports = getRecentReports(); // Last 24 hours
  const anomalies = await detectAnomalies(recentReports);
  
  if (anomalies.includes(true)) {
    alert('‚ö†Ô∏è Unusual activity detected in your area! Check the map for details.');
  }
}, 300000); // Check every 5 minutes

DEMO TALKING POINT:
"Using Azure Anomaly Detector, we can identify unusual patterns in real-time. If an area suddenly becomes much noisier than normal - like an unexpected event or accident - users get immediate alerts."

===========================================

5. QUICK SETUP INSTRUCTIONS

STEP 1: GET AZURE STUDENT ACCOUNT
- Go to azure.microsoft.com/free/students
- Sign up with your .edu email
- Get $100 free credit

STEP 2: CREATE YOUR CHOSEN SERVICE
- Follow steps in Option 1, 2, or 3 above
- Always choose FREE tier when available

STEP 3: GET YOUR CREDENTIALS
- After creating resource, go to "Keys and Endpoint"
- Copy KEY 1 and ENDPOINT
- Keep these secret!

STEP 4: ADD TO YOUR CODE
- Copy the code from your chosen option
- Replace YOUR_ENDPOINT_HERE and YOUR_KEY_HERE
- Test it!

STEP 5: UPDATE YOUR DEMO
- Add the talking points to your presentation
- Show the AI feature in your demo video
- Mention "Azure AI" prominently

===========================================

6. CODE IMPLEMENTATION - COMPLETE EXAMPLE

Here's how to integrate Option 1 (Sentiment Analysis) into your existing app:

// Add to script.js

const AZURE_LANGUAGE_ENDPOINT = 'YOUR_ENDPOINT_HERE';
const AZURE_LANGUAGE_KEY = 'YOUR_KEY_HERE';

async function analyzeSentiment(description) {
  try {
    const response = await fetch(`${AZURE_LANGUAGE_ENDPOINT}/text/analytics/v3.1/sentiment`, {
      method: 'POST',
      headers: {
        'Ocp-Apim-Subscription-Key': AZURE_LANGUAGE_KEY,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({
        documents: [{ 
          id: '1', 
          language: 'en',
          text: description 
        }]
      })
    });
    
    const data = await response.json();
    return data.documents[0].sentiment;
  } catch (error) {
    console.error('Sentiment analysis failed:', error);
    return 'neutral'; // Fallback
  }
}

// Update your existing reportNoiseZone function
async function reportNoiseZone(coords, level, description) {
  // Analyze sentiment with Azure AI
  const sentiment = await analyzeSentiment(description);
  
  // Adjust level based on AI analysis
  if (sentiment === 'negative') {
    level = Math.min(1.0, level + 0.2);
    console.log('Azure AI detected negative sentiment - increasing danger level');
  }
  
  // Save to backend with sentiment data
  fetch('http://localhost:3000/api/reports/noise', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({ coords, level, description, sentiment })
  })
  .then(res => res.json())
  .then(report => {
    communityReports.noise.push(report);
    addReportMarker(report, 'noise');
    updateReportsCount();
    alert(`‚úÖ Report submitted! Azure AI detected ${sentiment} sentiment.`);
  });
}

// Add to helpers.js - Update the report function
function reportCurrentLocation(type) {
  if (!navigator.geolocation) {
    alert('‚ùå Location not supported by your browser');
    return;
  }
  
  navigator.geolocation.getCurrentPosition(
    async (position) => {
      const coords = [position.coords.longitude, position.coords.latitude];
      
      // Get description from user
      const description = prompt('Describe the issue (e.g., "Heavy traffic, very loud"):');
      if (!description) return;
      
      if (type === 'noise') {
        await reportNoiseZone(coords, 0.9, description);
      } else if (type === 'crowd') {
        await reportCrowdedArea(coords, 0.8, description);
      }
    },
    (error) => {
      alert('‚ùå Please enable location access');
    }
  );
}

===========================================

7. DEMO TALKING POINTS FOR IMAGINE CUP

OPENING:
"Rivo Navigation uses Azure AI to make cities more accessible for people with sensory sensitivities."

DURING DEMO:
"Watch what happens when I report a noisy area. [Submit report with description 'Very loud, stressful traffic']

Our Azure AI Language service analyzes the description in real-time and detects the negative sentiment. It automatically increases the danger level of this zone, making our predictions more accurate for other users."

TECHNICAL EXPLANATION:
"We're using Azure's Text Analytics API with sentiment analysis. It processes natural language descriptions and returns positive, negative, or neutral sentiment scores. This helps us prioritize high-stress areas without manual review."

IMPACT STATEMENT:
"By integrating Azure AI, we've made our app smarter and more responsive. It learns from how users describe their experiences, not just what they report."

CLOSING:
"Azure AI enables us to scale this solution globally while maintaining accuracy and personalization for each user."

===========================================

8. TROUBLESHOOTING

ISSUE: "401 Unauthorized"
FIX: Check your API key is correct and hasn't expired

ISSUE: "CORS error"
FIX: Make sure you're calling from HTTPS (not HTTP) or add CORS headers to your backend

ISSUE: "Rate limit exceeded"
FIX: You're on free tier - wait a minute or upgrade

ISSUE: "Resource not found"
FIX: Check your endpoint URL is correct (should end with .cognitiveservices.azure.com)

===========================================

9. IMAGINE CUP SUBMISSION CHECKLIST

‚úì Azure service created and working
‚úì API keys secured (not in public code)
‚úì Feature demonstrated in video
‚úì "Azure AI" mentioned in presentation
‚úì Technical documentation updated
‚úì Code comments explain Azure integration
‚úì Fallback behavior if API fails
‚úì Cost estimate included (free tier)

===========================================

10. ADDITIONAL RESOURCES

Azure for Students: azure.microsoft.com/free/students
Azure AI Documentation: docs.microsoft.com/azure/cognitive-services
Imagine Cup Resources: imaginecup.microsoft.com/resources
Azure AI Samples: github.com/Azure-Samples

===========================================

FINAL TIPS FOR IMAGINE CUP SUCCESS

1. Start with Option 1 (Sentiment Analysis) - it's easiest and most reliable
2. Test thoroughly before your demo
3. Have a backup plan if internet fails during demo
4. Emphasize how AI improves user experience
5. Show before/after comparison (with vs without AI)
6. Mention "Azure" multiple times in your presentation
7. Include Azure logo in your slides
8. Explain why you chose Azure (scalability, reliability, student support)

Good luck with Imagine Cup! üèÜ

===========================================

Document Version: 1.0
Last Updated: 2024
Created for: Rivo Navigation - Imagine Cup Project
